{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini Project - Email classifier with Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"authors_file_path\": \"https://github.com/udacity/ud120-projects/blob/master/tools/email_authors.pkl\",\n",
    "    \"word_file_path\": \"https://github.com/udacity/ud120-projects/blob/master/tools/word_data.pkl\",\n",
    "    \"test_size\": 0.1,\n",
    "    \"random_state\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "marvin_cell": "acquisitor"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading files ....\n",
      "Loading files ....\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from marvin_python_toolbox.common.data import MarvinData\n",
    "import pickle\n",
    "import cPickle\n",
    "\n",
    "### the words (features) and authors (labels), already largely preprocessed\n",
    "### this preprocessing will be repeated in the text learning mini-project\n",
    "\n",
    "print \"Downloading files ....\"\n",
    "authors_file_path = MarvinData.download_file(params[\"authors_file_path\"])\n",
    "word_file_path = MarvinData.download_file(params[\"word_file_path\"])\n",
    "\n",
    "print \"Loading files ....\"\n",
    "authors_file_handler = open(authors_file_path, \"r\")\n",
    "authors = pickle.load(authors_file_handler)\n",
    "authors_file_handler.close()\n",
    "\n",
    "words_file_handler = open(word_file_path, \"r\")\n",
    "word_data = cPickle.load(words_file_handler)\n",
    "words_file_handler.close()\n",
    "\n",
    "initial_dataset = {\n",
    "    \"word_data\": word_data,\n",
    "    \"authors\": authors\n",
    "}\n",
    "\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "marvin_cell": "tpreparator"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/taka/.virtualenvs/ml-intro-engine-env/local/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no. of Chris training emails: 7936\n",
      "no. of Sara training emails: 7884\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "\n",
    "### test_size is the percentage of events assigned to the test set\n",
    "### (remainder go into training)\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(\n",
    "    initial_dataset[\"word_data\"], \n",
    "    initial_dataset[\"authors\"], \n",
    "    test_size=params[\"test_size\"], \n",
    "    random_state=params[\"random_state\"])\n",
    "\n",
    "### text vectorization--go from strings to lists of numbers\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, stop_words='english')\n",
    "features_train_transformed = vectorizer.fit_transform(features_train)\n",
    "features_test_transformed  = vectorizer.transform(features_test)\n",
    "\n",
    "### feature selection, because text is super high dimensional and \n",
    "### can be really computationally chewy as a result\n",
    "selector = SelectPercentile(f_classif, percentile=10)\n",
    "selector.fit(features_train_transformed, labels_train)\n",
    "\n",
    "features_train_transformed = selector.transform(features_train_transformed).toarray()\n",
    "features_test_transformed  = selector.transform(features_test_transformed).toarray()\n",
    "\n",
    "### info on the data\n",
    "print \"no. of Chris training emails:\", sum(labels_train)\n",
    "print \"no. of Sara training emails:\", len(labels_train) - sum(labels_train)\n",
    "\n",
    "dataset = {\n",
    "    \"features_train_transformed\": features_train_transformed,\n",
    "    \"features_test_transformed\": features_test_transformed,\n",
    "    \"labels_train\": labels_train,\n",
    "    \"labels_test\": labels_test\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "marvin_cell": "trainer"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting traning process...\n",
      "training time: 137.849 s\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "    This is the code to accompany the Lesson 2 (SVM) mini-project. \n",
    "\n",
    "    Use a Support Vector Machine to identify emails by their authors\n",
    "    \n",
    "    authors and labels:\n",
    "    Sara has label 0\n",
    "    Chris has label 1\n",
    "\"\"\"\n",
    "from sklearn.svm import SVC\n",
    "from time import time\n",
    "\n",
    "print \"Starting traning process...\"\n",
    "t0 = time()\n",
    "\n",
    "clf = SVC(kernel=\"rbf\", C=10000)\n",
    "\n",
    "clf.fit(dataset[\"features_train_transformed\"], dataset[\"labels_train\"])\n",
    "\n",
    "print \"training time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "model = clf\n",
    "\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "marvin_cell": "evaluator"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction time: 13.984 s\n",
      "the accuracy score is  0.990898748578\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from time import time\n",
    "\n",
    "t0 = time()\n",
    "y_pred = model.predict(dataset[\"features_test_transformed\"])\n",
    "print \"prediction time:\", round(time()-t0, 3), \"s\"\n",
    "\n",
    "accuracy_score = accuracy_score(dataset[\"labels_test\"], y_pred)\n",
    "\n",
    "print \"the accuracy score is \", accuracy_score\n",
    "metrics = {\"accuracy_score\": accuracy_score}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
